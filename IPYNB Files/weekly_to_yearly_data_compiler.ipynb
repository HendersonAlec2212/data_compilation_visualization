{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b4a7667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36334ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def files_to_lists(file_folder):\n",
    "    '''    finds files in folder specified by directory\n",
    "\n",
    "           return list of file_names and list of file_paths respectively\n",
    "\n",
    "       :param: file_folder - dtype:string -  the name / file path from current working directory to directory for\n",
    "       collecting filenames/filepaths\n",
    "\n",
    "       :return: separate lists of both file_name and file_path\n",
    "\n",
    "    '''\n",
    "    # assign directory\n",
    "    directory = f'{file_folder}/'\n",
    "    file_name_list = []\n",
    "    file_path_list = []\n",
    "\n",
    "    # iterate over files in\n",
    "    # that directory\n",
    "    for filename in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        # checking if it is a file\n",
    "        if os.path.isfile(file_path):\n",
    "            # if true: frop file name and path into list as string\n",
    "            file_name_list.append(filename)\n",
    "            file_path_list.append(file_path) \n",
    "    return file_name_list, file_path_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f8a7a0",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6103eb5d",
   "metadata": {},
   "source": [
    "# Sales Summary Break Down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2258bed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sales_summary_cleaner(xls,date):\n",
    "    '''\n",
    "    Sales Summary is a combination of three dataframes, so we will\n",
    "    \n",
    "    Take the Sales Summary WKS and break it into parts - Labor, Cogs, and Freebies.\n",
    "    \n",
    "    Then transform the pieces into individual DFs, and create a master DF of all information.\n",
    "    \n",
    "    Then return all 4 dfs in dictionary\n",
    "    \n",
    "    :param: xls --> xls = pd.ExcelFile(file_path) in worksheets_to_df()\n",
    "\n",
    "    :param: date --> date = meta_data['Unnamed: 4'][0] # week ending date in worksheets_to_df()\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    sales_summary = pd.read_excel(xls, 'Sales Summary')\n",
    "    \n",
    "    # set up cols for parsing\n",
    "    \n",
    "    sales_and_cogs_query_cols = sales_summary[f'{sales_summary.columns[0]}'].to_list()\n",
    "    labor_cost_summary_cols = sales_summary[f'{sales_summary.columns[5]}'].to_list()\n",
    "\n",
    "    # create dictionary to hold the cleaned DFs\n",
    "    sales_summary_dfs = {}\n",
    "    # if a string from the cols matches target, set i for start and end points\n",
    "    for i in sales_summary.index.to_list():\n",
    "        # --------------- Freebies --------------- #\n",
    "        if sales_and_cogs_query_cols[i] == 'Manager Freebies':\n",
    "            freebies_promos_start = i\n",
    "\n",
    "        elif sales_and_cogs_query_cols[i] == 'Total Freebies':\n",
    "            freebies_promos_end = i+1\n",
    "\n",
    "        # --------------- COGS --------------- #\n",
    "        if sales_and_cogs_query_cols[i] == 'COGS Summary':\n",
    "            cogs_start = i+1\n",
    "\n",
    "        elif sales_and_cogs_query_cols[i] == 'Total Sales':\n",
    "            cogs_end = i\n",
    "\n",
    "        # --------------- Labor Cost Summary --------------- #\n",
    "        if labor_cost_summary_cols[i] == 'Labor Cost Summary':\n",
    "            labor_summary_start = i+1\n",
    "\n",
    "        elif labor_cost_summary_cols[i] == 'Total Labor Cost':\n",
    "            labor_summary_end = i+1\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "    # turn the start and end points into dfs using iloc to slice\n",
    "    freebies_promos = sales_summary.iloc[freebies_promos_start:freebies_promos_end]\n",
    "    cogs = sales_summary.iloc[cogs_start:cogs_end]\n",
    "    labor_summary = sales_summary.iloc[labor_summary_start:labor_summary_end]\n",
    "\n",
    "\n",
    "        # --------------------------------------------- Freebies --------------------------------------------- #\n",
    "\n",
    "\n",
    "    # keep only first two columns\n",
    "    freebies_promos = freebies_promos[['Summary Report (V2)','Unnamed: 1']]\n",
    "\n",
    "    freebies_promos = freebies_promos.T\n",
    "\n",
    "    # reset index\n",
    "    freebies_promos = freebies_promos.reset_index(drop=True)\n",
    "    # rename column\n",
    "    freebies_promos.columns=freebies_promos.iloc[0]\n",
    "    # drop col used for labels\n",
    "    freebies_promos = freebies_promos.drop(0)\n",
    "    # insert week ending date\n",
    "    freebies_promos.insert(0,'week_ending_date',date)\n",
    "    # reset index\n",
    "    freebies_promos = freebies_promos.reset_index(drop=True)\n",
    "\n",
    "        # --------------------------------------------- cogs --------------------------------------------- #\n",
    "\n",
    "    # set df to these cols from parent DF\n",
    "    cogs = cogs[['Summary Report (V2)','Unnamed: 1']]\n",
    "    # remove NaN\n",
    "    cogs = cogs.dropna(how='all', axis=0).reset_index(drop=True)\n",
    "    # transpose df\n",
    "    cogs = cogs.T\n",
    "    # set column labels\n",
    "    cogs.columns = cogs.iloc[0]\n",
    "    # remove name\n",
    "    cogs.columns.name = None\n",
    "    # add week ending date\n",
    "    cogs.insert(0,'week_ending_date',date)\n",
    "    # reset index and drop col name row\n",
    "    cogs = cogs.reset_index(drop=True).drop(0).reset_index(drop=True)\n",
    "\n",
    "\n",
    "        # --------------------------------------------- labor summary --------------------------------------------- #\n",
    "\n",
    "    # Take the df apart and slap it together such that its formatted as desired\n",
    "\n",
    "    # slice the bits wanted, set the cols, \n",
    "\n",
    "    labor_summary_usd = labor_summary[['Unnamed: 5','Unnamed: 7']].T.reset_index(drop=True)\n",
    "    labor_summary_usd.columns = labor_summary_usd.iloc[0]\n",
    "#     labor_summary_prcnt = labor_summary[['Unnamed: 5','Unnamed: 6']].T.reset_index(drop=True)\n",
    "#     labor_summary_prcnt.columns = labor_summary_prcnt.iloc[0]\n",
    "\n",
    "    # merge with suffixes to identify cols\n",
    "    labor_summary = labor_summary_usd #.join(labor_summary_prcnt, how='outer', lsuffix='_usd', rsuffix='_prcnt_as_dec')\n",
    "    #remove label row\n",
    "    labor_summary = labor_summary.drop(0)\n",
    "    # add week ending date\n",
    "    labor_summary.insert(0,'week_ending_date',date)\n",
    "\n",
    "\n",
    "        # --------------------------------------------- full summary --------------------------------------------- #\n",
    "    # merge all dfs to have master df\n",
    "    cogs_and_labor = cogs.merge(labor_summary, how='outer')\n",
    "    cogs_labor_freebies = cogs_and_labor.merge(freebies_promos, how='outer')\n",
    "    full_summary = cogs_labor_freebies.dropna(how='all', axis=1)\n",
    "\n",
    "\n",
    "    sales_summary_dfs['freebies_promos'] = freebies_promos\n",
    "    sales_summary_dfs['cogs'] = cogs\n",
    "    sales_summary_dfs['labor_summary'] = labor_summary\n",
    "    sales_summary_dfs['full_sales_summary'] = full_summary\n",
    "\n",
    "    \n",
    "    \n",
    "    return sales_summary_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9793c80",
   "metadata": {},
   "source": [
    "# Gross Sales Break Down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe8d47d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gross_sales_cleaner(xls,date):\n",
    "    '''\n",
    "        :param: xls --> \"xls = pd.ExcelFile(file_path)\" in worksheets_to_df()\n",
    "\n",
    "        :param: date --> \"date = meta_data['Unnamed: 4'][0] # week ending date\" in worksheets_to_df()\n",
    "    '''\n",
    "    \n",
    "    gross_sales = pd.read_excel(xls, 'Gross Sales')\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        strings= gross_sales['Statement of Gross Sales (V2)'].to_list()\n",
    "\n",
    "        gross_sales_dfs = {}\n",
    "\n",
    "        for i,string in enumerate(strings):\n",
    "            '''\n",
    "            The gross_sales is a combination of four dataframes in one XLS sheet.\n",
    "\n",
    "            The goal of this section of script is to take the four DFs, parse the starting and\n",
    "            stopping points of the information, then cut out and format the DFs\n",
    "            so that they can be combined with future DFs from the following weeks.\n",
    "\n",
    "\n",
    "\n",
    "            '''\n",
    "\n",
    "            #--------------------------------- daily_sales    --------------------------------- #\n",
    "            if string == 'Day':\n",
    "                d_sales_start = i+1\n",
    "\n",
    "            elif string == 'Tuesday':\n",
    "                d_sales_end = i+1\n",
    "\n",
    "            #--------------------------------- fees_and_payments    --------------------------------- #\n",
    "            elif string == 'Fees and Payments':\n",
    "                fees_and_payments_start = i\n",
    "\n",
    "            elif string == 'Media - at 3% of Royalty Sales':\n",
    "                fees_and_payments_end = i+1\n",
    "\n",
    "            #--------------------------------- inventory_summary    --------------------------------- #\n",
    "            elif string == 'Bread 4311':\n",
    "                inventory_summary_start = i\n",
    "\n",
    "            elif string == 'Discounted COGS':\n",
    "                inventory_summary_end = i+1\n",
    "\n",
    "            #--------------------------------- shift_sales_summary    --------------------------------- #\n",
    "            elif string == 'Shift - 1 Wed AM':\n",
    "                shift_sales_summary_start = i\n",
    "\n",
    "            elif string == 'Royalty Sales':\n",
    "                shift_sales_summary_end = i+1\n",
    "\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        # cut out the DFs from the messy XLS\n",
    "        daily_sales = gross_sales.iloc[d_sales_start:d_sales_end]\n",
    "        fees_and_payments = gross_sales.iloc[fees_and_payments_start:fees_and_payments_end]\n",
    "        inventory_summary = gross_sales.iloc[inventory_summary_start:inventory_summary_end]\n",
    "        shift_sales_summary = gross_sales.iloc[shift_sales_summary_start:shift_sales_summary_end]\n",
    "\n",
    "    # ---------------------------- Daily Sales ---------------------------- #\n",
    "        # name columns\n",
    "        daily_sales.columns = ['Day',\n",
    "         'Date',\n",
    "         'No. Of Sales',\n",
    "         '(A) Total Dollar Sales',\n",
    "         '(B) Net Less Over rings',\n",
    "         '(C) Less Net Promo',\n",
    "         '(D) Net Less Employee Freebies',\n",
    "         '(E) Royalty Sales']\n",
    "        \n",
    "        # perform data aggregations\n",
    "        try:\n",
    "            dollars_per_sale = daily_sales['No. Of Sales'] / daily_sales['(A) Total Dollar Sales']\n",
    "        except ZeroDivisionError:\n",
    "            dollars_per_sale = 0\n",
    "        \n",
    "        \n",
    "        # remove name \"4\" for cleaner look\n",
    "        daily_sales.columns.name = None\n",
    "        \n",
    "        # insert new columns / aggregations\n",
    "        daily_sales.insert(0,'week_ending_date',date)\n",
    "        daily_sales.insert(3, 'dollars_per_sales',dollars_per_sale)\n",
    "        \n",
    "        # reset the index\n",
    "        daily_sales = daily_sales.reset_index(drop=True)\n",
    "\n",
    "\n",
    "    # ---------------------------- Fees and Payments ---------------------------- #\n",
    "\n",
    "        #remove NaN in rows and columns\n",
    "        fees_and_payments = fees_and_payments.dropna(how='all', axis=0).dropna(how='all', axis=1)\n",
    "\n",
    "        # rest index to allow for droppping of first row in case of formatting changes later on\n",
    "        fees_and_payments = fees_and_payments.reset_index(drop=True)\n",
    "        fees_and_payments = fees_and_payments.drop(0).reset_index(drop=True)\n",
    "\n",
    "        # set up lists to hold values for inserting in DF\n",
    "        payment_type = []\n",
    "        prcnt_of_royalty_sales = []\n",
    "\n",
    "        # for each line in DF, extract values and push to list\n",
    "\n",
    "        ### I want to have separate columns for the type of payment, and the percent paid\n",
    "        ### in event of changes later I want to able to record / manipulate them as desired without editing at later stage\n",
    "\n",
    "        for i in fees_and_payments.index.to_list():\n",
    "            payment_type.append(fees_and_payments['Statement of Gross Sales (V2)'][i].split(' ')[0])\n",
    "            prcnt_of_royalty_sales.append(fees_and_payments['Statement of Gross Sales (V2)'][i].split(' ')[3][:-1])\n",
    "\n",
    "        # insert new columns into previous DF\n",
    "        fees_and_payments.insert(0,'week_ending_date',date)\n",
    "        fees_and_payments.insert(1,'payment_type',payment_type)\n",
    "        fees_and_payments.insert(2,'prcnt_of_royalty_sales',prcnt_of_royalty_sales)\n",
    "\n",
    "        # rename cols\n",
    "        fees_and_payments = fees_and_payments.rename(columns={'Unnamed: 3':'fee_or_payment','Unnamed: 4':'amount'})\n",
    "\n",
    "        # srop column used to acqurie info as it is not needed anymore\n",
    "        fees_and_payments = fees_and_payments.drop(columns=['Statement of Gross Sales (V2)'])\n",
    "\n",
    "    # ---------------------------- Inventory Summary ---------------------------- #\n",
    "        # remove and fill NaN\n",
    "        inventory_summary = inventory_summary.dropna(how='all', axis=1).dropna(how='all', axis=0).fillna(0)\n",
    "\n",
    "        # rename the columns\n",
    "        inventory_summary = inventory_summary.rename(columns={\n",
    "                                                            'Statement of Gross Sales (V2)':'Category',\n",
    "                                                            'Unnamed: 1':'Beginning Inventory USD',\n",
    "                                                            'Unnamed: 2':'Purchases USD',\n",
    "                                                            'Unnamed: 3':'Ending Inventory USD',\n",
    "                                                            'Unnamed: 4':'COGS Prcnt as Decimal',})\n",
    "        # insert the week_ending_date\n",
    "        inventory_summary.insert(0,'week_ending_date',date)\n",
    "\n",
    "    # ---------------------------- Shift Sales Summary ---------------------------- #\n",
    "\n",
    "\n",
    "        # remove NaN values\n",
    "        shift_sales_summary = shift_sales_summary.dropna(how='all', axis=1).dropna(how='all', axis=0)\n",
    "\n",
    "        # transpose the dataframe to allow shifts to be the columns\n",
    "        shift_sales_summary = shift_sales_summary.T\n",
    "\n",
    "        # mass rename columns\n",
    "        shift_sales_summary.columns = shift_sales_summary.iloc[0]\n",
    "\n",
    "        # reset index and remove wor used for column names\n",
    "        shift_sales_summary = shift_sales_summary.reset_index(drop=True).drop(0)\n",
    "\n",
    "        # insert date\n",
    "        shift_sales_summary.insert(0,'week_ending_date',date)\n",
    "\n",
    "        # remove column.name for prettify purposes\n",
    "        shift_sales_summary.columns.name = None\n",
    "\n",
    "    # ---------------------------- set up return dictionary ---------------------------- #\n",
    "        gross_sales_dfs['daily_sales'] = daily_sales\n",
    "        gross_sales_dfs['fees_and_payments'] = fees_and_payments\n",
    "        gross_sales_dfs['inventory_summary'] = inventory_summary\n",
    "        gross_sales_dfs['shift_sales_summary'] = shift_sales_summary\n",
    "\n",
    "        return gross_sales_dfs\n",
    "    \n",
    "    except KeyError:\n",
    "        return\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72470ec",
   "metadata": {},
   "source": [
    "# Petty Cash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "137ae6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def petty_cash_cleaner(xls, date):\n",
    "    '''\n",
    "        :param: xls --> \"xls = pd.ExcelFile(file_path)\" in worksheets_to_df()\n",
    "\n",
    "        :param: date --> \"date = meta_data['Unnamed: 4'][0] # week ending date\" in worksheets_to_df()\n",
    "    '''\n",
    "\n",
    "    # load in the snippet from XLS\n",
    "    petty_cash = pd.read_excel(xls, 'Petty Cash', skiprows=(7))\n",
    "    # define a starting point for duplicating date across cells\n",
    "    date_cell = 2\n",
    "    for i in range(0,8):\n",
    "        try :\n",
    "            petty_cash.iloc[1,date_cell+1] = petty_cash.iloc[1,date_cell]\n",
    "            date_cell+=2\n",
    "        except IndexError:\n",
    "            print()\n",
    "            continue\n",
    "    # fill NA\n",
    "    petty_cash = petty_cash.fillna(0)\n",
    "\n",
    "    # set new column names for reformatting\n",
    "    cols = [\n",
    "        'Account Name', 'Account Number', 'Wed - 1', 'Wed - 2', 'Thu - 3', 'Thu - 4', 'Fri - 5', 'Fri - 6', 'Sat - 7', 'Sat - 8', 'Sun - 9', 'Sun - 10', 'Mon - 11', 'Mon - 12', 'Tue - 13', 'Tue - 14', 'Account.1', 'Totals',\n",
    "    ]\n",
    "\n",
    "    # Set names of all columns\n",
    "    petty_cash.columns = cols\n",
    "\n",
    "    # define and inset new columns to reduce redundant info\n",
    "    newcol = petty_cash['Account Name'].astype(str) + ' - ' + petty_cash['Account Number'].astype(str)\n",
    "    petty_cash.insert(0, \"Account\", newcol)\n",
    "\n",
    "    # drop un wanted columns and rows\n",
    "    petty_cash = petty_cash.drop(columns=['Account.1', 'Account Name', 'Account Number'])\n",
    "    petty_cash = petty_cash.drop([0])\n",
    "\n",
    "    petty_cash.insert(0,'week_ending_date',date)\n",
    "    return petty_cash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5671f0",
   "metadata": {},
   "source": [
    "# Master Food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96ffcc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def food_cleaner(xls,date):\n",
    "    '''\n",
    "        :param: xls --> \"xls = pd.ExcelFile(file_path)\" in worksheets_to_df()\n",
    "\n",
    "        :param: date --> \"date = meta_data['Unnamed: 4'][0] # week ending date\" in worksheets_to_df()\n",
    "    '''\n",
    "    # load in the snippet from XLS\n",
    "    master_food = pd.read_excel(xls, 'Master Voucher Food', skiprows=(6))\n",
    "    # remove all NaN\n",
    "    master_food = master_food.fillna(0)\n",
    "\n",
    "    # transpose to make columns the item being purchased\n",
    "    master_food = master_food.T\n",
    "\n",
    "    # set columns names to transposed DF row values\n",
    "    master_food.columns = master_food.iloc[0]\n",
    "\n",
    "    # remove name of columns resulting from previous transformation\n",
    "    master_food.columns.name = None\n",
    "\n",
    "    # drop the row used to make column names, and the row with current week totals.\n",
    "    master_food = master_food.reset_index(drop=True)\n",
    "\n",
    "    # setup index\n",
    "    index_list = master_food.index.to_list()\n",
    "\n",
    "    # conditional to drop the first and last row of the DF\n",
    "    for i in index_list:\n",
    "        if (master_food['Due Date'][i] == \"Due Date\") or (master_food['Due Date'][i] == \"Account\"):\n",
    "            master_food = master_food.drop([i])\n",
    "        else: \n",
    "            continue\n",
    "    master_food.insert(0,'week_ending_date',date)\n",
    "    # reset index\n",
    "    master_food = master_food.reset_index(drop=True)\n",
    "    return master_food"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091d91fe",
   "metadata": {},
   "source": [
    "# Master Produce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e742f57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_cleaner(xls,date):\n",
    "    '''\n",
    "        :param: xls --> \"xls = pd.ExcelFile(file_path)\" in worksheets_to_df()\n",
    "\n",
    "        :param: date --> \"date = meta_data['Unnamed: 4'][0] # week ending date\" in worksheets_to_df()\n",
    "    '''\n",
    "    # load in the snippet from XLS        \n",
    "    master_produce = pd.read_excel(xls, 'Master Voucher Produce', skiprows=(6))\n",
    "    #  transpose to simplify the data sheet\n",
    "    master_produce = master_produce.T\n",
    "\n",
    "    # drop NaN column\n",
    "    master_produce = master_produce.dropna(how='all', axis=1)\n",
    "\n",
    "    # remove NaN \n",
    "    master_produce = master_produce.fillna(0)\n",
    "\n",
    "    # reset the index to remove the column names\n",
    "    master_produce = master_produce.reset_index(drop=True)\n",
    "\n",
    "    #  set columns == first row (which was the 'column' header in the XLS)\n",
    "    master_produce.columns = master_produce.iloc[0]\n",
    "\n",
    "    # setup index\n",
    "    index_list = master_produce.index.to_list()\n",
    "\n",
    "    # # conditional to drop the first and last row of the DF\n",
    "    for i in index_list:\n",
    "        if (master_produce['Due Date'][i] == \"Due Date\") or (master_produce['Due Date'][i] == \"Account\"):\n",
    "            master_produce = master_produce.drop([i])\n",
    "        else: \n",
    "            continue\n",
    "    master_produce.insert(0,'week_ending_date',date)\n",
    "    # reset index\n",
    "    master_produce = master_produce.reset_index(drop=True)\n",
    "    return master_produce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bf5933",
   "metadata": {},
   "source": [
    "# Labor Managers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49c2a18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labor_manager_cleaner(xls, date):\n",
    "    '''\n",
    "        :param: xls --> \"xls = pd.ExcelFile(file_path)\" in worksheets_to_df()\n",
    "\n",
    "        :param: date --> \"date = meta_data['Unnamed: 4'][0] # week ending date\" in worksheets_to_df()\n",
    "    '''\n",
    "    \n",
    "    labor_managers = pd.read_excel(xls, 'Labor Managers')\n",
    "    try:\n",
    "        # set strings to use for parsing\n",
    "        string_list = labor_managers['PAYROLL TIME SHEET - Manager (V2)'].to_list()\n",
    "        if len(string_list) <=0:\n",
    "            return None\n",
    "        else:\n",
    "            # if string == parsed word, record i and use to set up DF snippet\n",
    "            for i, string in enumerate(string_list):\n",
    "                if string =='Manager':\n",
    "                    start_i = i\n",
    "                elif string == 'TOTAL WEEKLY    $':\n",
    "                    ending_i = i\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            # set up snippet\n",
    "            labor_manager_summary = labor_managers.iloc[start_i:ending_i]\n",
    "            # remove NaN Cols\n",
    "            labor_manager_summary = labor_manager_summary.dropna(how='all',axis=1)\n",
    "            # Split DFs then merge with suffxies to avoid having to rename each col\n",
    "            labor_manager_summary_usd = labor_manager_summary[['PAYROLL TIME SHEET - Manager (V2)','Unnamed: 2']].T.reset_index(drop=True)\n",
    "            labor_manager_summary_usd.columns = labor_manager_summary_usd.iloc[0]\n",
    "\n",
    "            labor_manager_summary_prcnt = labor_manager_summary[['PAYROLL TIME SHEET - Manager (V2)','Unnamed: 3']].T.reset_index(drop=True)\n",
    "            labor_manager_summary_prcnt.columns = labor_manager_summary_prcnt.iloc[0]\n",
    "\n",
    "\n",
    "            # merge with suffixes to identify cols\n",
    "            labor_manager_summary = labor_manager_summary_usd.join(labor_manager_summary_prcnt, how='outer', lsuffix='_usd', rsuffix='_prcnt_as_dec')\n",
    "            #remove label row\n",
    "            labor_manager_summary = labor_manager_summary.drop(0)\n",
    "            # add week ending date\n",
    "            labor_manager_summary.insert(0,'week_ending_date',date)\n",
    "            return labor_manager_summary\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69daa62b",
   "metadata": {},
   "source": [
    "# Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8df8523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inventory_cleaner(xls,date):\n",
    "    '''\n",
    "        :param: xls --> \"xls = pd.ExcelFile(file_path)\" in worksheets_to_df()\n",
    "\n",
    "        :param: date --> \"date = meta_data['Unnamed: 4'][0] # week ending date\" in worksheets_to_df()\n",
    "    '''\n",
    "        # read in the file\n",
    "    inventory = pd.read_excel(xls, 'Inventory')\n",
    "    # remove NaN\n",
    "    inventory = inventory.fillna(0)\n",
    "\n",
    "    # rename cols to ease concat later\n",
    "    inventory = inventory.rename(columns={\n",
    "        'INVENTORY (V2)':'item',\n",
    "        'Unnamed: 1':'units_of_measure',\n",
    "        'Unnamed: 2':'beginning_units',\n",
    "        'Unnamed: 3':'unit_purchases_1',\n",
    "        'Unnamed: 4':'unit_purchases_2',\n",
    "        'Unnamed: 5':'unit_purchases_3',\n",
    "        'Unnamed: 6':'unit_purchases_4',\n",
    "        'Unnamed: 7':'total_purchased',\n",
    "        'Unnamed: 8':'on_hand_counts',\n",
    "        'Unnamed: 9':'ending_units',\n",
    "        'Unnamed: 10':'unit_cost',\n",
    "        'Unnamed: 11':'ending_value_usd',\n",
    "        'Unnamed: 12':'usage_units',\n",
    "    })\n",
    "    # one column is a float for some reason - converting to string to keep all cols in same dtype\n",
    "    inventory['unit_purchases_3'] = inventory['unit_purchases_3'].astype(int).astype(str)\n",
    "    # make a list to allow for iteration even if the inventory length changes\n",
    "    inventory_index_list = inventory.index.to_list()\n",
    "\n",
    "    # create a list to hold sections of dataframe\n",
    "    inventory_slice_list = []\n",
    "    for i in inventory_index_list:\n",
    "\n",
    "        # define row\n",
    "        row = inventory.iloc[i]\n",
    "\n",
    "        # set conditionals to identify when to start recording the inventory\n",
    "        if row['item'] == 'Item':\n",
    "            # start_i = i+3 b/c I want to remove the two redundant column rows from XLS without pd.df.drop()\n",
    "            start_i = i+3\n",
    "            category = inventory.iloc[i+2]['item']\n",
    "    #         print(f'start_i is {start_i}')\n",
    "    #         print(f'category is {category}')\n",
    "\n",
    "\n",
    "        # set conditionals to identify when to stop recording the inventory\n",
    "        if row['item'] == \"Beginning Inventory $'s\":\n",
    "            ending_i = i\n",
    "    #         print(f'ending_i is {ending_i}')\n",
    "    #         print()\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # define the dataframe object\n",
    "        inventory_slice = inventory.iloc[start_i:ending_i]\n",
    "\n",
    "        # insert aggregated data into the dataframe\n",
    "    #             inventory_slice.insert(1,'week_ending',week_ending)\n",
    "\n",
    "        inventory_slice.insert(1,'week_ending',date)\n",
    "        inventory_slice.insert(2,'category',category)\n",
    "\n",
    "        # add piece to list for combining later\n",
    "        inventory_slice_list.append(inventory_slice)\n",
    "\n",
    "    # combine the pieces into one master inventory for the week\n",
    "    inventory = pd.concat(inventory_slice_list)\n",
    "    inventory = inventory.reset_index(drop=True)\n",
    "    \n",
    "    return inventory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f17e43",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80496bdf",
   "metadata": {},
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9518c7f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def take_input():\n",
    "    '''\n",
    "    this function requests years of the files that are desired to be compiled.\n",
    "    \n",
    "    the years will work with the :worksheets_to_df(): function to produce a dictionary of dataframes that will be used\n",
    "        in later functions\n",
    "        \n",
    "    :return:\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    print('Field 1 of 2:')\n",
    "    print('Typing numbers only with no spaces or punctuation, input the year you would like to START file combination')\n",
    "    print()\n",
    "\n",
    "    start_year = input('If you wish to use for just one year, enter the same value in for both fields. ')\n",
    "    start_year = int(start_year)\n",
    "    print()\n",
    "    print()\n",
    "    print('Field 2 of 2:')\n",
    "    print('Typing numbers only with no spaces or punctuation, input the year you would like to STOP file combination')\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "    end_year = input('If you wish to use for just one year, enter the same value in for both fields. ')\n",
    "    end_year = int(end_year)\n",
    "    print()\n",
    "\n",
    "    print('Inputs recieved, Starting concatination...')\n",
    "    return start_year, end_year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ab07c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_and_format_DF(dataframe_list):\n",
    "    \n",
    "    '''\n",
    "    Accepts list of dataframes, concats into single DF, resets the index -dropping the initial index- then returns \n",
    "    a single dataframe unless there is no data for concat. \n",
    "    \n",
    "    If no data, will return None Object\n",
    "    \n",
    "    \n",
    "    :param: dataframe_list --> list of dataframes\n",
    "    \n",
    "    :return_try: --> returns a concatinated dataframe\n",
    "    \n",
    "    :return_except: --> return None\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        dataframe = pd.concat(dataframe_list)\n",
    "    \n",
    "        dataframe = dataframe.reset_index(drop=True).fillna(0)\n",
    "\n",
    "        return dataframe\n",
    "    \n",
    "    except:\n",
    "        print()\n",
    "        print('No Data to concatinate - Returning \"None\" Data.')\n",
    "        print('===================================================')\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44ed32a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worksheets_to_df(start_year,end_year):\n",
    "    '''\n",
    "        :param: start/end_year - integer --> value used in \"file_name_list, file_path_list = files_to_lists(f'{year}/')\"\n",
    "            for assembly of file paths used for later functions, and as a primary key in the return_dict.\n",
    "            \n",
    "        :return: dictionary of all files as concatinated dataframes organized by primary key, (year)\n",
    "                 and secondary key, (name of dataframe).\n",
    "    \n",
    "        - Takes start and end year of sales to clean and combine; the year is also the file name in original directory.\n",
    "\n",
    "        - Converts XLS to Dataframe.\n",
    "\n",
    "        - Snips out desired data using various methods, cleans and transfers each week as DF to list.\n",
    "\n",
    "        - Converts each week_df into master_df per Work Sheet using pd.concat\n",
    "                resulting in a DF for each Work Sheet for each year.\n",
    "\n",
    "        - Returns dictionary of each master DF labeled by worksheet -> \n",
    "        return_dict{\n",
    "                    ['year']{\n",
    "                    ['worksheet_name']:df_of_worksheet,\n",
    "                    ['worksheet_name']:df_of_worksheet,\n",
    "                            },\n",
    "\n",
    "    '''\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    return_dict = {}\n",
    "    \n",
    "    \n",
    "    \n",
    "    for year in range(start_year,end_year+1):\n",
    "        \n",
    "        return_dict[f'{year}'] = {}\n",
    "        print('- Dictionary for dataframe return successfully constructed...')\n",
    "        print()\n",
    "\n",
    "        # in the event that file names are desired to be preserved\n",
    "        file_name_list, file_path_list = files_to_lists(f'{year}/')\n",
    "        # make lists to hold the DFs\n",
    "\n",
    "        # --------- sales summary --------- #\n",
    "        sales_summary_list = []\n",
    "        cogs_list = []\n",
    "        labor_list = []\n",
    "        promo_list = []\n",
    "\n",
    "        # --------- gross sales --------- #\n",
    "        daily_sales_list = []\n",
    "        fees_and_payments_list = []\n",
    "        inventory_summary_list = []\n",
    "        shift_sales_summary_list = []\n",
    "\n",
    "        # --------- weekly sales --------- #\n",
    "        weekly_sales_list = []\n",
    "\n",
    "        # --------- petty cash --------- #\n",
    "        petty_cash_list = []\n",
    "\n",
    "        # --------- master voucher food  --------- #\n",
    "\n",
    "        master_food_list = []\n",
    "\n",
    "        # --------- master voucher produce  --------- #\n",
    "\n",
    "        master_produce_list = []\n",
    "\n",
    "        # --------- Inventory --------- #\n",
    "        inventory_list = []\n",
    "\n",
    "        # --------- Labor Managers --------- #\n",
    "        labor_managers_list = []\n",
    "\n",
    "        print(f'- Lists for pd.concat {year} successfully made...')\n",
    "        print('===========================================')\n",
    "        print()\n",
    "\n",
    "\n",
    "\n",
    "        # --------- --------- --------- --------- --------- --------- --------- --------- --------- --------- --------- #\n",
    "\n",
    "\n",
    "        # for each file in the folder read these columns/rows,\n",
    "        # set == these variables,\n",
    "        # assign those variables to a dictionary with the Ending Week Date as a common value across all\n",
    "        # turn that dictionary into a Dataframe for later saving as CSV\n",
    "\n",
    "        for i,file_path in enumerate(file_path_list):\n",
    "\n",
    "            try:\n",
    "                worksheet = 'Meta Data'\n",
    "\n",
    "                xls = pd.ExcelFile(file_path)\n",
    "                meta_data = pd.read_excel(xls, 'Sales Summary', nrows=4)\n",
    "\n",
    "                # ------------------------------------------------------------------- #\n",
    "                date = meta_data['Unnamed: 4'][0] # week ending date\n",
    "                store_num = meta_data['Unnamed: 4'][2]\n",
    "                print()\n",
    "\n",
    "\n",
    "            except ValueError:\n",
    "                print('File Type Not Supported, Skipping File...')\n",
    "                print('===========================================')\n",
    "                print('')\n",
    "                continue           \n",
    "\n",
    "\n",
    "        # ------------------------------------------------ sales summary ------------------------------------------------- #\n",
    "        # ------------------------------------------------ sales summary ------------------------------------------------- #\n",
    "        # ------------------------------------------------ sales summary ------------------------------------------------- #\n",
    "\n",
    "\n",
    "            try:\n",
    "                worksheet = 'Sales Summary'\n",
    "\n",
    "                sales_summary_dfs = sales_summary_cleaner(xls,date)\n",
    "\n",
    "                sales_summary_list.append(sales_summary_dfs['full_sales_summary'])\n",
    "                cogs_list.append(sales_summary_dfs['cogs'])\n",
    "                labor_list.append(sales_summary_dfs['labor_summary'])\n",
    "                promo_list.append(sales_summary_dfs['freebies_promos'])\n",
    "\n",
    "\n",
    "            except ValueError: # if Worksheet is not found in XLS\n",
    "                print(f'Worksheet {worksheet} not in XLS file, moving on...')\n",
    "                print('===========================================')\n",
    "                print('')\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "        # ------------------------------------------------ gross sales ------------------------------------------------- #\n",
    "        # ------------------------------------------------ gross sales ------------------------------------------------- #\n",
    "        # ------------------------------------------------ gross sales ------------------------------------------------- #\n",
    "\n",
    "\n",
    "            try:\n",
    "                worksheet = 'Gross Sales'\n",
    "\n",
    "                gross_sales_dfs = gross_sales_cleaner(xls,date)\n",
    "\n",
    "                daily_sales_list.append(gross_sales_dfs['daily_sales'])\n",
    "                fees_and_payments_list.append(gross_sales_dfs['fees_and_payments'])\n",
    "                inventory_summary_list.append(gross_sales_dfs['inventory_summary'])\n",
    "                shift_sales_summary_list.append(gross_sales_dfs['shift_sales_summary'])\n",
    "\n",
    "\n",
    "            except (ValueError, TypeError): # if Worksheet is not found in XLS\n",
    "                print(f'Worksheet {worksheet} not in XLS file, moving on...')\n",
    "                print('===========================================')\n",
    "                print('')\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "        # ------------------------------------------------ Weekly Sales ------------------------------------------------- #\n",
    "        # ------------------------------------------------ Weekly Sales ------------------------------------------------- #\n",
    "        # ------------------------------------------------ Weekly Sales ------------------------------------------------- #\n",
    "\n",
    "            try:\n",
    "                worksheet = 'Weekly Sales'\n",
    "\n",
    "                # load in the snippet from XLS\n",
    "                weekly_sales = pd.read_excel(xls, 'Weekly Sales', skiprows=(7))\n",
    "\n",
    "                # drop rows that hold the date and AM/PM b/c duplicated information is not wanted\n",
    "                weekly_sales = weekly_sales.drop([0,1])\n",
    "\n",
    "                # rename the columns\n",
    "                weekly_sales = weekly_sales.rename(columns={\n",
    "                    'Summary':'Revenue_USD',\n",
    "                    '#EA':'Quantity Sold',\n",
    "                })\n",
    "\n",
    "                # fill NA\n",
    "                weekly_sales = weekly_sales.fillna(0)\n",
    "\n",
    "                #insert week ending date\n",
    "                weekly_sales.insert(0,'week_ending_date',date)\n",
    "\n",
    "                # reset the index\n",
    "                weekly_sales = weekly_sales.reset_index(drop=True)\n",
    "\n",
    "                # add finished DF to list for later concat.\n",
    "                weekly_sales_list.append(weekly_sales)\n",
    "\n",
    "\n",
    "            except ValueError: # if Worksheet is not found in XLS\n",
    "                print(f'Worksheet {worksheet} not in XLS file, moving on...')\n",
    "                print('===========================================')\n",
    "                print('')\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # ------------------------------------------------ Petty Cash ------------------------------------------------- #\n",
    "        # ------------------------------------------------ Petty Cash ------------------------------------------------- #\n",
    "        # ------------------------------------------------ Petty Cash ------------------------------------------------- #\n",
    "\n",
    "\n",
    "\n",
    "            try:\n",
    "                worksheet = 'Petty Cash'\n",
    "\n",
    "                petty_cash = petty_cash_cleaner(xls,date)\n",
    "\n",
    "                # add finished DF to list for later concat.\n",
    "                petty_cash_list.append(petty_cash)\n",
    "\n",
    "\n",
    "            except ValueError: # if Worksheet is not found in XLS\n",
    "                print(f'Worksheet {worksheet} not in XLS file, moving on...')\n",
    "                print('===========================================')\n",
    "                print('')\n",
    "                continue\n",
    "\n",
    "\n",
    "    # ------------------------------------------------ Master Voucher Food ------------------------------------------------- #\n",
    "    # ------------------------------------------------ Master Voucher Food ------------------------------------------------- #\n",
    "    # ------------------------------------------------ Master Voucher Food ------------------------------------------------- #\n",
    "\n",
    "\n",
    "\n",
    "            try:\n",
    "                worksheet = 'Master Food'\n",
    "\n",
    "                master_food = food_cleaner(xls,date)\n",
    "\n",
    "                # add finished DF to list for later concat.\n",
    "                master_food_list.append(master_food)\n",
    "\n",
    "\n",
    "            except ValueError: # if Worksheet is not found in XLS\n",
    "                print(f'Worksheet {worksheet} not in XLS file, moving on...')\n",
    "                print('===========================================')\n",
    "                print('')\n",
    "                continue\n",
    "\n",
    "    # ------------------------------------------------ Master Voucher Produce ---------------------------------------------- #\n",
    "    # ------------------------------------------------ Master Voucher Produce ---------------------------------------------- #\n",
    "    # ------------------------------------------------ Master Voucher Produce ---------------------------------------------- #\n",
    "\n",
    "\n",
    "\n",
    "            try:\n",
    "                worksheet = 'Master Produce'\n",
    "\n",
    "                master_produce = produce_cleaner(xls,date)\n",
    "\n",
    "                # add finished DF to list for later concat\n",
    "                master_produce_list.append(master_produce)\n",
    "\n",
    "\n",
    "            except ValueError: # if Worksheet is not found in XLS\n",
    "                print(f'Worksheet {worksheet} not in XLS file, moving on...')\n",
    "                print('===========================================')\n",
    "                print('')\n",
    "                continue\n",
    "\n",
    "    # ------------------------------------------------ Inventory ------------------------------------------------- #\n",
    "    # ------------------------------------------------ Inventory ------------------------------------------------- #\n",
    "    # ------------------------------------------------ Inventory ------------------------------------------------- #\n",
    "\n",
    "\n",
    "            try:\n",
    "                worksheet = 'Inventory'\n",
    "\n",
    "                inventory = inventory_cleaner(xls,date)\n",
    "\n",
    "                inventory_list.append(inventory)\n",
    "\n",
    "            except ValueError: # if Worksheet is not found in XLS\n",
    "                print(f'Worksheet {worksheet} not in XLS file, moving on...')\n",
    "                print('===========================================')\n",
    "                print('')\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "    # ------------------------------------------------ Labor Managers ------------------------------------------------- #\n",
    "    # ------------------------------------------------ Labor Managers ------------------------------------------------- #\n",
    "    # ------------------------------------------------ Labor Managers ------------------------------------------------- #\n",
    "\n",
    "\n",
    "            try:\n",
    "                print()\n",
    "                print(f'File # {i} of {len(file_path_list)} for year {year} compiled')\n",
    "                print(f' ------ Week Ending Date {date} ------ ')\n",
    "                print('=======================================================')\n",
    "\n",
    "\n",
    "                worksheet = 'Labor Managers'\n",
    "\n",
    "                labor_managers = labor_manager_cleaner(xls,date)\n",
    "\n",
    "                labor_managers_list.append(labor_managers)\n",
    "\n",
    "            except ValueError: # if Worksheet is not found in XLS\n",
    "                print(f'Worksheet {worksheet} not in XLS file, moving on...')\n",
    "                print('===========================================')\n",
    "                print('')\n",
    "                continue\n",
    "\n",
    "\n",
    "# ============================================= DATAFRAME CREATION =============================================== #\n",
    "\n",
    "        # define list to hold final Dataframes\n",
    "\n",
    "        # concat all dataframes from lists of dictionaries\n",
    "\n",
    "        # --------- sales summary --------- #\n",
    "        year_end_cogs_df = concat_and_format_DF(cogs_list)\n",
    "        year_end_labor_df = concat_and_format_DF(labor_list)\n",
    "        year_end_promo_df = concat_and_format_DF(promo_list)\n",
    "        sales_summary_df = concat_and_format_DF(sales_summary_list)\n",
    "\n",
    "        # --------- gross sales --------- #\n",
    "\n",
    "        daily_sales_df = concat_and_format_DF(daily_sales_list)\n",
    "        fees_and_payments_df = concat_and_format_DF(fees_and_payments_list)\n",
    "        inventory_summary_df = concat_and_format_DF(inventory_summary_list)\n",
    "        shift_sales_summary_df = concat_and_format_DF(shift_sales_summary_list)\n",
    "\n",
    "\n",
    "        # --------- weekly sales --------- #\n",
    "        weekly_sales_df = concat_and_format_DF(weekly_sales_list)\n",
    "\n",
    "        # --------- petty cash --------- #\n",
    "        petty_cash_df = concat_and_format_DF(petty_cash_list)\n",
    "\n",
    "        # --------- master voucher food --------- #\n",
    "        master_food_df = concat_and_format_DF(master_food_list)\n",
    "\n",
    "        # --------- master voucher produce --------- #\n",
    "        master_produce_df = concat_and_format_DF(master_produce_list)\n",
    "\n",
    "        # --------- inventory --------- #\n",
    "        inventory_df = concat_and_format_DF(inventory_list)\n",
    "\n",
    "        # --------- labor managers --------- #\n",
    "        labor_manager_summary_df = concat_and_format_DF(labor_managers_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # ================================================= FUNCTION RETURNS ================================================== #\n",
    "\n",
    "        # add cleaned DFs to list in dictionary for later iteration in worksheets to CSV function\n",
    "\n",
    "        # Sales Summary #\n",
    "        return_dict[f'{year}']['sales_summary'] = sales_summary_df\n",
    "\n",
    "        return_dict[f'{year}']['freebies_and_promos'] = year_end_promo_df\n",
    "\n",
    "        return_dict[f'{year}']['cogs'] = year_end_cogs_df\n",
    "\n",
    "        return_dict[f'{year}']['labor'] = year_end_labor_df\n",
    "\n",
    "        # Gross Sales #\n",
    "        return_dict[f'{year}']['daily_sales'] = daily_sales_df\n",
    "\n",
    "        return_dict[f'{year}']['fees_and_payments'] = fees_and_payments_df\n",
    "\n",
    "        return_dict[f'{year}']['inventory_summary'] = inventory_summary_df\n",
    "\n",
    "        return_dict[f'{year}']['shift_sales_summary'] = shift_sales_summary_df\n",
    "\n",
    "\n",
    "        # Weekly Sales #\n",
    "        return_dict[f'{year}']['weekly_sales'] = weekly_sales_df\n",
    "\n",
    "        # Petty Cash #\n",
    "        return_dict[f'{year}']['petty_cash'] = petty_cash_df\n",
    "\n",
    "        # Master Voucher Food #\n",
    "        return_dict[f'{year}']['master_food'] = master_food_df\n",
    "\n",
    "        # Master Voucher Produce #\n",
    "        return_dict[f'{year}']['master_produce'] = master_produce_df\n",
    "\n",
    "        # Inventory #\n",
    "        return_dict[f'{year}']['inventory'] = inventory_df    \n",
    "\n",
    "\n",
    "        # Labor Manager Summary #\n",
    "        return_dict[f'{year}']['labor_manager_summary'] = labor_manager_summary_df\n",
    "\n",
    "\n",
    "\n",
    "        print()\n",
    "        print('====================================')\n",
    "        print(f'Files processed for year {year}.')\n",
    "        print('====================================')\n",
    "        print()\n",
    "\n",
    "\n",
    "    return return_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ab7316",
   "metadata": {},
   "source": [
    "_________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d75c7007",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def dictionary_dataframes_to_csv(dictionary_of_dataframes):\n",
    "    \n",
    "    '''\n",
    "    :param: dictionary_of_dataframes - a dictionary with the years as primary keys and the files as secondary keys\n",
    "        see function -> worksheets_to_df(start_year,end_year)\n",
    "\n",
    "        for each primary_key or year in dict_o_dataframes\n",
    "        make a list of the DFs in the sub-dict\n",
    "        nav to HOME > make new DIR for year\n",
    "            \n",
    "            then\n",
    "            \n",
    "        for each file in sub-dict:\n",
    "            extract info such as the year and name of file > save file as CSV\n",
    "            REPEAT\n",
    "        ------------------------------------------------------------------------------------------------\n",
    "            \n",
    "    resulting file structure - compiled data>\n",
    "                                            year>\n",
    "                                                file01.csv\n",
    "                                                file01.csv\n",
    "                                                file03.csv\n",
    "                                            year>\n",
    "                                                etc.\n",
    "\n",
    "\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # sets home as current working directory\n",
    "    home = os.getcwd()\n",
    "    \n",
    "    # sets up primary keys for iteration through years of dictionary O' dataframes.\n",
    "    years_list = list(dictionary_of_dataframes.keys())\n",
    "    \n",
    "    # sets the name of the directory to create, that will house all of the newly cruched CSVs\n",
    "    compiled_dir = 'compiled_data'\n",
    "    for file_year in years_list:\n",
    "        # nav to Home Directory\n",
    "        os.chdir(home)\n",
    "\n",
    "        files_list = list(dictionary_of_dataframes[f'{file_year}'].keys())\n",
    "        print()\n",
    "        print()\n",
    "        print(' --------------------- BEGIN SAVING OF DATAFRAMES as CSV --------------------- ')\n",
    "        print()\n",
    "        print(' ---------------------------------------------------------------------------------------- ')\n",
    "        print(f'Current Working Directory is {os.getcwd()}')\n",
    "        print(' ---------------------------------------------------------------------------------------- ')\n",
    "        try:\n",
    "            print(f'Attempting to create directory for {compiled_dir}...')\n",
    "            print(f'')\n",
    "            os.mkdir(f'{home}/{compiled_dir}')\n",
    "            os.chdir(f'{home}/{compiled_dir}')\n",
    "\n",
    "        except FileExistsError:\n",
    "            print(f'Directory {compiled_dir} Already Exists, Moving into {compiled_dir}... ')\n",
    "            print(f'')\n",
    "            os.chdir(f'{home}/{compiled_dir}')\n",
    "\n",
    "        try:\n",
    "            print(f'Attempting to create directory for {file_year}...')\n",
    "            print(f'')\n",
    "            os.mkdir(f'{home}/{compiled_dir}/{file_year}')\n",
    "            os.chdir(f'{home}/{compiled_dir}/{file_year}')\n",
    "\n",
    "        except FileExistsError:\n",
    "            print(f'Directory {file_year} Already Exists, Moving into {file_year}... ')\n",
    "            print(f'')\n",
    "            os.chdir(f'{home}/{compiled_dir}/{file_year}')\n",
    "\n",
    "\n",
    "        for file in files_list:\n",
    "            try:\n",
    "                print(f'Saving {file_year}_{file} as CSV')\n",
    "                dictionary_of_dataframes[f'{file_year}'][f'{file}'].to_csv(f'{file_year}_{file}.csv', index=False)        \n",
    "                print('=======================')\n",
    "                print()\n",
    "            except:\n",
    "                print(f'Issue detected with {file}, it may not exist. Moving on..')\n",
    "                print()\n",
    "\n",
    "        print(f'Resetting Directory to {home}')\n",
    "        os.chdir(f'{home}')\n",
    "        print()\n",
    "        print(f'Current Working Directory is {os.getcwd()}')\n",
    "        print()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1255a17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Dictionary for dataframe return successfully constructed...\n",
      "\n",
      "- Lists for pd.concat 2014 successfully made...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n",
      "Worksheet Gross Sales not in XLS file, moving on...\n",
      "===========================================\n",
      "\n",
      "\n",
      "No Data to concatinate - Returning \"None\" Data.\n",
      "===================================================\n",
      "\n",
      "No Data to concatinate - Returning \"None\" Data.\n",
      "===================================================\n",
      "\n",
      "No Data to concatinate - Returning \"None\" Data.\n",
      "===================================================\n",
      "\n",
      "No Data to concatinate - Returning \"None\" Data.\n",
      "===================================================\n",
      "\n",
      "No Data to concatinate - Returning \"None\" Data.\n",
      "===================================================\n",
      "\n",
      "No Data to concatinate - Returning \"None\" Data.\n",
      "===================================================\n",
      "\n",
      "No Data to concatinate - Returning \"None\" Data.\n",
      "===================================================\n",
      "\n",
      "No Data to concatinate - Returning \"None\" Data.\n",
      "===================================================\n",
      "\n",
      "No Data to concatinate - Returning \"None\" Data.\n",
      "===================================================\n",
      "\n",
      "No Data to concatinate - Returning \"None\" Data.\n",
      "===================================================\n",
      "\n",
      "====================================\n",
      "Files processed for year 2014.\n",
      "====================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# start_year,end_year = take_input()\n",
    "\n",
    "dataframe_dictionary = worksheets_to_df(start_year,end_year)\n",
    "\n",
    "# dictionary_dataframes_to_csv(dataframe_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84d070d",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55140de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sales_summary', 'freebies_and_promos', 'cogs', 'labor', 'daily_sales', 'fees_and_payments', 'inventory_summary', 'shift_sales_summary', 'weekly_sales', 'petty_cash', 'master_food', 'master_produce', 'inventory', 'labor_manager_summary'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_dictionary['2014'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8af6bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcafbf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1a72b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sales_list = []\n",
    "fees_and_payments_list = []\n",
    "inventory_summary_list = []\n",
    "shift_sales_summary_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ffaa6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_list, file_path_list = files_to_lists(f'2014')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24724097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!! get_externsheet_local_range: refx=11, not in range(1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xls = pd.ExcelFile(file_path_list[0])\n",
    "\n",
    "meta_data = pd.read_excel(xls, 'Sales Summary', nrows=4)\n",
    "\n",
    "# ------------------------------------------------------------------- #\n",
    "date = meta_data['Unnamed: 4'][0] # week ending date\n",
    "store_num = meta_data['Unnamed: 4'][2]\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b15e3482",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gross_sales = pd.read_excel(xls, 'Gross Sales')\n",
    "\n",
    "strings= gross_sales['Statement of Gross Sales (V2)'].to_list()\n",
    "\n",
    "gross_sales_dfs = {}\n",
    "\n",
    "for i,string in enumerate(strings):\n",
    "    '''\n",
    "    The gross_sales is a combination of four dataframes in one XLS sheet.\n",
    "\n",
    "    The goal of this section of script is to take the four DFs, parse the starting and\n",
    "    stopping points of the information, then cut out and format the DFs\n",
    "    so that they can be combined with future DFs from the following weeks.\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "    #--------------------------------- daily_sales    --------------------------------- #\n",
    "    if string == 'Day':\n",
    "        d_sales_start = i+1\n",
    "\n",
    "    elif string == 'Tuesday':\n",
    "        d_sales_end = i+1\n",
    "\n",
    "    #--------------------------------- fees_and_payments    --------------------------------- #\n",
    "    elif string == 'Fees and Payments':\n",
    "        fees_and_payments_start = i\n",
    "\n",
    "    elif string == 'Media - at 3% of Royalty Sales':\n",
    "        fees_and_payments_end = i+1\n",
    "\n",
    "    #--------------------------------- inventory_summary    --------------------------------- #\n",
    "    elif string == 'Bread 4311':\n",
    "        inventory_summary_start = i\n",
    "\n",
    "    elif string == 'Discounted COGS':\n",
    "        inventory_summary_end = i+1\n",
    "\n",
    "    #--------------------------------- shift_sales_summary    --------------------------------- #\n",
    "    elif string == 'Shift - 1 Wed AM':\n",
    "        shift_sales_summary_start = i\n",
    "\n",
    "    elif string == 'Royalty Sales':\n",
    "        shift_sales_summary_end = i+1\n",
    "\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# cut out the DFs from the messy XLS\n",
    "daily_sales = gross_sales.iloc[d_sales_start:d_sales_end]\n",
    "fees_and_payments = gross_sales.iloc[fees_and_payments_start:fees_and_payments_end]\n",
    "inventory_summary = gross_sales.iloc[inventory_summary_start:inventory_summary_end]\n",
    "shift_sales_summary = gross_sales.iloc[shift_sales_summary_start:shift_sales_summary_end]\n",
    "\n",
    "# ---------------------------- Daily Sales ---------------------------- #\n",
    "# name columns\n",
    "daily_sales.columns = ['Day',\n",
    " 'Date',\n",
    " 'No. Of Sales',\n",
    " '(A) Total Dollar Sales',\n",
    " '(B) Net Less Over rings',\n",
    " '(C) Less Net Promo',\n",
    " '(D) Net Less Employee Freebies',\n",
    " '(E) Royalty Sales']\n",
    "\n",
    "# perform data aggregations\n",
    "# if daily_sales['(A) Total Dollar Sales'] <= 0:\n",
    "#     dollars_per_sale = daily_sales['(A) Total Dollar Sales'] / daily_sales['No. Of Sales']\n",
    "# else:\n",
    "#     dollars_per_sale = 0\n",
    "\n",
    "\n",
    "# remove name \"4\" for cleaner look\n",
    "daily_sales.columns.name = None\n",
    "\n",
    "# insert new columns / aggregations\n",
    "daily_sales.insert(0,'week_ending_date',date)\n",
    "# daily_sales.insert(3, 'dollars_per_sales',dollars_per_sale)\n",
    "\n",
    "# reset the index\n",
    "daily_sales = daily_sales.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "573a1c27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week_ending_date</th>\n",
       "      <th>Day</th>\n",
       "      <th>Date</th>\n",
       "      <th>No. Of Sales</th>\n",
       "      <th>(A) Total Dollar Sales</th>\n",
       "      <th>(B) Net Less Over rings</th>\n",
       "      <th>(C) Less Net Promo</th>\n",
       "      <th>(D) Net Less Employee Freebies</th>\n",
       "      <th>(E) Royalty Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/21/2014</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2014-01-15 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/21/2014</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>2014-01-16 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/21/2014</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2014-01-17 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/21/2014</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2014-01-18 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/21/2014</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2014-01-19 00:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01/21/2014</td>\n",
       "      <td>Monday</td>\n",
       "      <td>2014-01-20 00:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>01/21/2014</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2014-01-21 00:00:00</td>\n",
       "      <td>138</td>\n",
       "      <td>1184.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.46</td>\n",
       "      <td>1149.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  week_ending_date        Day                 Date No. Of Sales  \\\n",
       "0       01/21/2014  Wednesday  2014-01-15 00:00:00            0   \n",
       "1       01/21/2014   Thursday  2014-01-16 00:00:00            0   \n",
       "2       01/21/2014     Friday  2014-01-17 00:00:00            0   \n",
       "3       01/21/2014   Saturday  2014-01-18 00:00:00            0   \n",
       "4       01/21/2014     Sunday  2014-01-19 00:00:00            6   \n",
       "5       01/21/2014     Monday  2014-01-20 00:00:00            5   \n",
       "6       01/21/2014    Tuesday  2014-01-21 00:00:00          138   \n",
       "\n",
       "  (A) Total Dollar Sales (B) Net Less Over rings (C) Less Net Promo  \\\n",
       "0                      0                       0                  0   \n",
       "1                      0                       0                  0   \n",
       "2                      0                       0                  0   \n",
       "3                      0                       0                  0   \n",
       "4                      0                       0                  0   \n",
       "5                      0                       0                  0   \n",
       "6                1184.31                       0                  0   \n",
       "\n",
       "  (D) Net Less Employee Freebies (E) Royalty Sales  \n",
       "0                              0                 0  \n",
       "1                              0                 0  \n",
       "2                              0                 0  \n",
       "3                              0                 0  \n",
       "4                              0                 0  \n",
       "5                              0                 0  \n",
       "6                          34.46           1149.85  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "51b3ae76",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-3d8a2450d13e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdollar_sales\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdaily_sales\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'(A) Total Dollar Sales'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mdollar_sales\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sjsjs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1440\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1442\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   1443\u001b[0m             \u001b[1;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1444\u001b[0m             \u001b[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "test = daily_sales.copy()\n",
    "num_sales = daily_sales['No. Of Sales']\n",
    "dollar_sales = daily_sales['(A) Total Dollar Sales']\n",
    "\n",
    "if dollar_sales <= 0:\n",
    "    print('sjsjs')\n",
    "\n",
    "# test['new_col'] = num_sales / dollar_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29083857",
   "metadata": {},
   "outputs": [],
   "source": [
    "need means of creating the dollars per transaction per week for vis purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c710458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
